{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")  \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-base\").to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b39a3cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(\"Bầu trời hôm nay rất đẹp và\", return_tensors=\"pt\").cuda()\n",
    "output = model.generate(\n",
    "    tokens, max_new_tokens=300, use_cache = True # by default is set to True\n",
    ")\n",
    "output_text = tokenizer.batch_decode(output, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea2b3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* và rất nhiều mây. Bầu trời hôm nay rất đẹp và rất nhiều mây. Bầu trời hôm nay rất đẹp và rất nhiều mây. Bầu trời hôm nay rất đẹp và rất nhiều mây. Bầu trời hôm nay rất đẹp và rất nhiều mây. Bầu trời hôm nay rất đẹp và rất nhiều mây. Bầu trời hôm nay rất đẹp và rất nhiều mây. Bầu trời hôm nay rất đẹp và rất nhiều mây. Bầu trời hôm nay rất đẹp và rất nhiều mây. Bầu trời hôm nay rất đẹp và rất đẹp. Bầu trời hôm nay rất đẹp và rất đẹp. Bầu trời hôm nay rất đẹp và rất đẹp. Bầu trời hôm nay rất đẹp và rất đẹp. Bầu trời hôm nay rất đẹp và rất đẹp. Bầu trời hôm nay rất đẹp và rất đẹp. Bầu trời hôm nay rất đẹp và rất đẹp. Bầu trời hôm nay rất đẹp và rất đẹp. Bầu trời hôm nay rất đẹp và rất đẹp. Bầu trời hôm nay rất đẹp và rất đẹp. Bầu trời rất đẹp và rất đẹp. Bầu trời rất đẹp và rất đẹp. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa6562f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_seq_length = 5\n",
    "dim_model = 10\n",
    "\n",
    "input_ids_emb = torch.randn(input_seq_length, dim_model)\n",
    "W_q = torch.randn(dim_model, dim_model)\n",
    "W_k = torch.randn(dim_model, dim_model)\n",
    "W_v = torch.randn(dim_model, dim_model)\n",
    "\n",
    "Q = input_ids_emb @ W_q\n",
    "K = input_ids_emb @ W_k\n",
    "V = input_ids_emb @ W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c90bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "d_k = K.shape[-1]\n",
    "attention_scores = (Q @ K.T) / math.sqrt(d_k)\n",
    "\n",
    "# Lower triangular mask to prevent future token access\n",
    "causal_mask = torch.tril(torch.ones(input_seq_length, input_seq_length))\n",
    "masked_scores = attention_scores.masked_fill(causal_mask == 0, float('-inf'))\n",
    "\n",
    "attention_weights = F.softmax(masked_scores, dim=-1)\n",
    "output = attention_weights @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84000080",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_token_emb = torch.randn(1, dim_model)\n",
    "extended_input = torch.cat([input_ids_emb, new_token_emb], dim=0)\n",
    "\n",
    "Q_ext = extended_input @ W_q\n",
    "K_ext = extended_input @ W_k\n",
    "V_ext = extended_input @ W_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78145570",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(K, K_ext[:input_seq_length]) # test pass\n",
    "torch.testing.assert_close(V, V_ext[:input_seq_length]) # test pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5da6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x, cos, sin, attention_mask=None, block_kv_cache=None):\n",
    "    is_prefill = block_kv_cache is None\n",
    "    B, T_curr, C = x.size()\n",
    "\n",
    "    # Project inputs to Q, K, V\n",
    "    q_curr, k_curr, v_curr = project_current_tokens(x)\n",
    "    q, k_rotated = apply_rotary_pos_embd(q_curr, k_curr, cos, sin)\n",
    "\n",
    "    if not is_prefill and block_kv_cache['key'] is not None:\n",
    "        # Append new keys and values to the cache\n",
    "        k = torch.cat([block_kv_cache['key'], k_rotated], dim=2)\n",
    "        v = torch.cat([block_kv_cache['value'], v_curr], dim=2)\n",
    "    else:\n",
    "        # First pass (prefill) — no cache\n",
    "        k, v = k_rotated, v_curr\n",
    "\n",
    "    block_kv_cache = {'key': k, 'value': v}\n",
    "    return attention_output, block_kv_cache\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
